

多模态系统通常由三个部分组成：

模态编码器 (Encoders)： 将不同输入（如图像、声音）转化为模型能理解的向量（Embeddings）。Embedding（嵌入）在机器学习和自然语言处理领域中是一个常见的概念，通常指的是将数据映射到一个低维度的向量空间的过程。在自然语言处理中，最常见的是词嵌入（Word Embeddings）。Word2Vec、GloVe 和 FastText 是一些流行的词嵌入模型

对齐机制 (Alignment)： 确保“猫”的文字向量和“猫”的图片向量在数学空间中是接近的。

生成/推理层 (LLM/Decoder)： 根据对齐后的信息生成结果。





目前的开发趋势主要分为：利用现成模型 API（如 Gemini, GPT-4o）以及使用开源框架自建/微调（如 Hugging Face, LangChain）


1. 闭源旗舰模型（API 驱动 / 行业基准）
OpenAI GPT-4o / o1 / o3,"GPT-4o, o3-mini",全能交互与复杂推理。 擅长实时语音通话、高难度逻辑推理（o系列）、视觉图表分析及代码生成。
Google Gemini,"Gemini 1.5 Pro/Flash, 2.0",超长上下文王。 1.5 Pro 支持高达 200 万 tokens，可一次性分析数小时视频、整本书或巨型代码库。
Anthropic Claude,Claude 3.5/3.7 Sonnet,代码与逻辑专家。 视觉理解极其精细，特别是在识别 UI 界面、复杂手写体和学术图表方面表现卓越。

2. 开源/国产领先模型（可本地部署 / 极具性价比）
DeepSeek (深度求索):

Janus-Pro: 采用解耦架构，既能理解图像也能生成高质量图像，是多模态理解与生成的平衡者。

DeepSeek-V3: 虽然主打文本，但其强大的推理能力使其在多模态插件调用中表现极佳。

Qwen-VL (阿里巴巴):

Qwen2.5-VL: 目前开源界的 SOTA（最高水平）。擅长视觉代理 (Visual Agent)，能直接模拟人类在手机或电脑屏幕上的点击操作。

InternVL (书生·河宣):

由上海 AI Lab 开发，专门针对超大规模图像和视频理解，特别适合工业视觉、遥感和复杂医学影像分析。

LLaVA (Open Source Pioneer):

最流行的多模态微调基础框架，适合开发者用来训练属于自己的垂直领域识图模型。