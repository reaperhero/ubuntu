# kafka config配置


| 来源                                  | 配置项                                                       | 配置功能                                                     | 默认值                                                       | 备注                                                         |
| :------------------------------------ | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| 来源                                  | 配置项                                                       | 配置功能                                                     | 默认值                                                       | 备注                                                         |
| consumer                              | enable.auto.commit                                           | consumer所fetch的消息的offset是否要自动的同步到zookeeper     | true                                                         | 建议false，先消费处理成功再commit，避免丢失消息/重复消费     |
| auto.commit.interval.ms               | 如果是自动commit模式，指定自动提交的间隔                     | 5000                                                         |                                                              |                                                              |
| auto.offset.reset                     | 没有初始化offset或者offset被删除时，可以设置以下值：earliest：自动复位offset为最早.latest：自动复位offset为最新.none：如果没有发现offset则向消费者抛出异常.anything else：向消费者抛出异常。 | latest                                                       | 建议 earliest，并辅以消费去重                                |                                                              |
| offsets.retention.minutes             | 超过时间未进行 commit 就删除该consumer的commit offfset，删除长期离线的consumer的commit信息 | 1440(一天)                                                   | 如果服务长时间挂掉，将会造成严重影响                         |                                                              |
| fetch.min.bytes                       | 指定了消费者从服务器获取记录的最小字节数                     | 1                                                            | broker 在收到消费者的数据请求时，如果可用的数据量小于 fetch.min.bytes 指定的大小，那么它会等到有足够的可用数据时才把它返回给消费者。这样可以降低消费者和 broker 的工作负载 |                                                              |
| fetch.max.bytes                       | Fetch 请求最多返回的数据大小                                 | 50M                                                          |                                                              |                                                              |
| fetch.max.wait.ms                     | 指定 broker 的等待时间                                       | 500ms                                                        | 拉取阻塞时间，Kafka 在收到消费者的请求后，要么返回 fetch.min.bytes 数据，要么在 fetch.max.wait.ms 后返回所有可用的数据 |                                                              |
| max.partition.fetch.bytes             | 指定了服务器从每个分区里返回给消费者的最大字节数             | 1MB                                                          | max.partition.fetch.bytes 的值必须比 broker 能够接收的最大消息的字节数（通过 max.message.size 属性配置）大，否则消费者可能无法读取这些消息，导致消费者一直挂起重试。为消费者分配内存时要考虑（多个分区） |                                                              |
| session.timeout.ms                    | 指定了消费者在被认为掉线之前可以与服务器断开连接的时间       | 10000                                                        | 如果消费者没有在指定的时间内发送心跳给群组协调器，就被认为已经掉线，协调器就会触发reblance，把它的分区分配给群组里的其他消费者。该属性与 heartbeat.interval.ms 紧密相关。heartbeat.interval.ms 指定了 poll() 方法向协调器发送心跳的频率，session.timeout.ms 则指定了消费者可以多久不发送心跳。 故timeout 要 大于 interval，一般3倍 |                                                              |
| client.id                             | 任意字符串，broker 用它来标识从客户端发送过来的消息          |                                                              | 通常被用在日志、度量指标和配额里。在服务端的请求日志中能够通过逻辑应用名称来跟踪请求的来源，而不是只能通过IP和端口号跟进 |                                                              |
| max.poll.records                      | 单次poll调用返回的最大消息数量                               | 500                                                          |                                                              |                                                              |
| max.poll.interval.ms                  | 使用 Kafka 消费分组机制时，再次调用 poll 允许的最大间隔。如果在该时间内没有再次调用 poll，则认为该消费者已经失败，Broker 会重新发起 Rebalance 把分配给它的 partition 分配给其他消费者 | 300000                                                       | 要确保一次poll的数据量可以在 此值范围内消费完成并提交，否则频繁触发 rebalance 影响性能 |                                                              |
| auto.offset.reset                     | 没有初始化offset或者offset被删除时的offset策略               | latest                                                       | - earliest：自动复位offset为最早. - latest：自动复位offset为最新. - none：如果没有发现offset则向消费者抛出异常. |                                                              |
| producer                              | batch.size                                                   | 当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算（而不是消息个数）。当批次被填满，批次里的所有消息会被发送出去 | 16384                                                        | 结合 linger.ms 共同发挥作用                                  |
| [linger.ms](http://linger.ms/)        | 该参数指定了生产者在发送批次之前等待更多消息加入批次的时间。kafka生产者会在批次填满或linger.ms达到上限时把批次发送出去 | 0                                                            |                                                              |                                                              |
| retries                               | 生产者从服务器收到的错误有可能是临时性的错误（比如分区找不到首领）。在这种情况下， retries参数的值决定了生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试并返回错误 | 0                                                            | 对消息顺序有要求的，需要结合其它参数共同设置                 |                                                              |
| retry.backoff.ms                      | 重试失败请求之前等待的时间。避免在某些失败场景下高频的循环重复发送请求。 | 100                                                          |                                                              |                                                              |
| acks                                  | acks参数指定了必须要有多少个分区副本收到消息，生产者才认为该消息是写入成功的，这个参数对于消息是否丢失起着重要作用 | 1                                                            | - acks=0   表示生产者在成功写入消息之前不会等待任何来自服务器的响应 - acks=1   表示只要集群的leader分区副本接收到了消息，就会向生产者发送一个成功响应的ack - acks=all  表示只有所有参与复制的节点(ISR列表的副本)全部收到消息时，生产者才会接收到来自服务器的响应.可以确保不止一个Broker接收到了消息. 该模式的延迟会比较高（结合 broker 的 min.insync.replicas） |                                                              |
| buffer.memory                         | 该参数用来设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足。这个时候，send()方法调用要么被阻塞，要么抛出异常，取决于如何设置max.block.ms。 | 32M                                                          | 当生产者调用时send()，消息并不会立即发送，而是会添加到内部缓冲区中   使用多个线程共享kafka producer时，要确保 buffer.memory 不被频繁用尽。 |                                                              |
| max.block.ms                          | 该参数指定了在调用send()方法或使用partitionsFor()方法获取元数据时生产者的阻塞时间 | 60000                                                        |                                                              |                                                              |
| compression.type                      | 默认情况下，消息发送时不会被压缩。该参数可以设置为snappy 、gzip 或lz4 ，它指定了消息被发送给broker 之前使用哪一种压缩算也进行压缩 | none                                                         | 使用压缩可以降低网络传输开销和存储开销如果网络IO率先达到瓶颈，有效考虑此设置 |                                                              |
| max.in.flight.requests.per.connection | Producer的IO线程在单个Socket连接上能够发送未应答请求的最大数量。即客户端到服务端的网络上最多允许的请求数量。增加此值应该可以增加IO线程的吞吐量，从而整体上提升producer的性能。 | 5                                                            | 如果同时开启了重试机制，那么设置该参数大于1的话有可能造成消息的乱序。  如果发现producer的瓶颈在IO线程，同时各个broker端负载不高，那么可以尝试适当增加该值.过大增加该参数会造成producer的整体内存负担，同时还可能造成不必要的锁竞争反而会降低TPS |                                                              |
| max.request.size                      | Producer单次发往某个Borker的请求内容最大值                   | 1048576                                                      | 确保该值 小于 Broker 端设置的 message.max.bytes向kafka发送的消息应当做到精简，尽量减少消息体体积 |                                                              |
| client.id                             | 任意字符串，broker 用它来标识从客户端发送过来的消息          |                                                              | 在服务端的请求日志中能够通过逻辑应用名称来跟踪请求的来源，而不是只能通过IP和端口号跟进 |                                                              |
| broker                                | log.retention.hours                                          | kafka消息日志保存的时间，可以选择hours,minutes和ms           | 168                                                          | 超出后等待超出[log.segment.delete.delay.ms](http://log.segment.delete.delay.ms/) 后才物理删除 |
| log.cleanup.policy                    | 日志清理的策略                                               | delete                                                       | 只有delete和compact两种可选项                                |                                                              |
| log.segment.delete.delay.ms           | 日志文件被真正删除前的保留时间                               | 60000                                                        |                                                              |                                                              |
| offsets.retention.minutes             | 超过时间未进行 commit 就删除该consumer的commit offfset，删除长期离线的consumer的commit信息 | 1440                                                         | 如果服务长时间挂掉，将会造成严重影响，因为无法得知之前消费到的具体offset   该值一般要大于消息日志的保存时长（log.retention.minutes） |                                                              |
| enable.idempotence                    | 是否启用幂等                                                 | false                                                        | 当启用幂等时，会强制执行acks = all，retries> 1和max.inflight.requests.per.connection = 1。 没有这些配置的这些值，不能保证幂等。 如果这些设置未被应用程序显式覆盖，则在启用幂等时，生产者将设置acks = all，retries = Integer.MAX_VALUE和max.inflight.requests.per.connection = 1。 |                                                              |
| message.max.bytes                     | 消息体的最大大小，单位是字节                                 | 1048576                                                      |                                                              |                                                              |
| min.insync.replicas                   | 控制的是消息至少被写入到多少个副本才算是真正写入，           | 1                                                            | 设定为一个大于1的值可以提升消息的持久性. 因为如果同步副本的数量低于该配置值，则生产者会收到错误响应，从而确保消息不丢失.（配合acks） |                                                              |
| auto.create.topics.enable             | 是否允许自动创建topic                                        | true                                                         | 从安全角度考虑，应禁用此功能                                 |                                                              |
| delete.topic.enable                   | 是否允许调用接口删除 Topic                                   | true                                                         | 从安全角度考虑，应禁用此功能                                 |                                                              |